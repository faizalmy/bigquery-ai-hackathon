"""
Error Handling and Retry Logic
Legal Document Intelligence Platform - BigQuery AI Hackathon Entry

This module provides comprehensive error handling, retry logic, and error classification
for the document processing pipeline.
"""

import logging
import time
from typing import Dict, List, Any, Optional, Callable, Tuple
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass
import traceback

logger = logging.getLogger(__name__)

class ErrorCategory(Enum):
    """Error categories for classification."""
    INPUT_VALIDATION = "input_validation"
    AI_MODEL = "ai_model"
    BIGQUERY = "bigquery"
    SYSTEM = "system"
    NETWORK = "network"
    TIMEOUT = "timeout"
    UNKNOWN = "unknown"

class ErrorSeverity(Enum):
    """Error severity levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class ProcessingError:
    """Structured error information."""
    error_id: str
    category: ErrorCategory
    severity: ErrorSeverity
    message: str
    exception: Optional[Exception]
    timestamp: datetime
    retryable: bool
    context: Dict[str, Any]
    stack_trace: Optional[str] = None

@dataclass
class RetryConfig:
    """Retry configuration for different error types."""
    max_retries: int
    base_delay: float
    max_delay: float
    exponential_base: float
    jitter: bool

class ErrorHandler:
    """
    Comprehensive error handling system with retry logic, error classification,
    and fallback strategies.
    """

    def __init__(self):
        """Initialize the error handler."""
        self.error_log = []
        self.retry_configs = self._initialize_retry_configs()
        self.error_patterns = self._initialize_error_patterns()
        self.fallback_strategies = self._initialize_fallback_strategies()

    def _initialize_retry_configs(self) -> Dict[ErrorCategory, RetryConfig]:
        """Initialize retry configurations for different error categories."""
        return {
            ErrorCategory.INPUT_VALIDATION: RetryConfig(
                max_retries=1,
                base_delay=1.0,
                max_delay=5.0,
                exponential_base=2.0,
                jitter=False
            ),
            ErrorCategory.AI_MODEL: RetryConfig(
                max_retries=3,
                base_delay=2.0,
                max_delay=30.0,
                exponential_base=2.0,
                jitter=True
            ),
            ErrorCategory.BIGQUERY: RetryConfig(
                max_retries=3,
                base_delay=1.0,
                max_delay=60.0,
                exponential_base=2.0,
                jitter=True
            ),
            ErrorCategory.SYSTEM: RetryConfig(
                max_retries=2,
                base_delay=5.0,
                max_delay=120.0,
                exponential_base=2.0,
                jitter=True
            ),
            ErrorCategory.NETWORK: RetryConfig(
                max_retries=5,
                base_delay=1.0,
                max_delay=30.0,
                exponential_base=2.0,
                jitter=True
            ),
            ErrorCategory.TIMEOUT: RetryConfig(
                max_retries=2,
                base_delay=10.0,
                max_delay=60.0,
                exponential_base=2.0,
                jitter=False
            ),
            ErrorCategory.UNKNOWN: RetryConfig(
                max_retries=2,
                base_delay=2.0,
                max_delay=20.0,
                exponential_base=2.0,
                jitter=True
            )
        }

    def _initialize_error_patterns(self) -> Dict[str, ErrorCategory]:
        """Initialize error pattern matching for automatic classification."""
        return {
            # Input validation errors
            "missing required field": ErrorCategory.INPUT_VALIDATION,
            "invalid format": ErrorCategory.INPUT_VALIDATION,
            "empty content": ErrorCategory.INPUT_VALIDATION,
            "content too short": ErrorCategory.INPUT_VALIDATION,
            "content too long": ErrorCategory.INPUT_VALIDATION,

            # AI model errors
            "model not found": ErrorCategory.AI_MODEL,
            "model error": ErrorCategory.AI_MODEL,
            "generation failed": ErrorCategory.AI_MODEL,
            "embedding failed": ErrorCategory.AI_MODEL,
            "prediction failed": ErrorCategory.AI_MODEL,

            # BigQuery errors
            "bigquery": ErrorCategory.BIGQUERY,
            "table not found": ErrorCategory.BIGQUERY,
            "dataset not found": ErrorCategory.BIGQUERY,
            "query failed": ErrorCategory.BIGQUERY,
            "permission denied": ErrorCategory.BIGQUERY,
            "quota exceeded": ErrorCategory.BIGQUERY,

            # System errors
            "memory": ErrorCategory.SYSTEM,
            "disk space": ErrorCategory.SYSTEM,
            "resource": ErrorCategory.SYSTEM,
            "connection": ErrorCategory.NETWORK,
            "timeout": ErrorCategory.TIMEOUT,
            "network": ErrorCategory.NETWORK
        }

    def _initialize_fallback_strategies(self) -> Dict[ErrorCategory, List[Callable]]:
        """Initialize fallback strategies for different error types."""
        return {
            ErrorCategory.AI_MODEL: [
                self._fallback_simple_extraction,
                self._fallback_keyword_analysis
            ],
            ErrorCategory.BIGQUERY: [
                self._fallback_local_storage,
                self._fallback_retry_later
            ],
            ErrorCategory.NETWORK: [
                self._fallback_offline_mode,
                self._fallback_cached_results
            ],
            ErrorCategory.TIMEOUT: [
                self._fallback_reduce_complexity,
                self._fallback_batch_processing
            ]
        }

    def handle_error(self, error: Exception, context: Dict[str, Any] = None) -> ProcessingError:
        """
        Handle and classify an error.

        Args:
            error: Exception that occurred
            context: Additional context information

        Returns:
            ProcessingError with classification and handling information
        """
        error_id = f"err_{int(time.time() * 1000)}"
        context = context or {}

        # Classify the error
        category = self._classify_error(error)
        severity = self._determine_severity(error, category)
        retryable = self._is_retryable(error, category)

        # Create structured error
        processing_error = ProcessingError(
            error_id=error_id,
            category=category,
            severity=severity,
            message=str(error),
            exception=error,
            timestamp=datetime.now(),
            retryable=retryable,
            context=context,
            stack_trace=traceback.format_exc()
        )

        # Log the error
        self._log_error(processing_error)

        return processing_error

    def execute_with_retry(self, func: Callable, *args, **kwargs) -> Tuple[Any, Optional[ProcessingError]]:
        """
        Execute a function with retry logic based on error classification.

        Args:
            func: Function to execute
            *args: Function arguments
            **kwargs: Function keyword arguments

        Returns:
            Tuple of (result, error) where result is the function output or None if failed
        """
        last_error = None

        for attempt in range(1, 4):  # Default max 3 attempts
            try:
                logger.info(f"ðŸ”„ Executing function (attempt {attempt})")
                result = func(*args, **kwargs)
                logger.info(f"âœ… Function executed successfully on attempt {attempt}")
                return result, None

            except Exception as e:
                last_error = self.handle_error(e, {
                    'function': func.__name__,
                    'attempt': attempt,
                    'args': str(args)[:100],  # Truncate for logging
                    'kwargs': str(kwargs)[:100]
                })

                # Check if error is retryable
                if not last_error.retryable:
                    logger.error(f"âŒ Non-retryable error: {last_error.message}")
                    return None, last_error

                # Check if we've exceeded max retries
                if attempt >= 3:
                    logger.error(f"âŒ Max retries exceeded for function {func.__name__}")
                    return None, last_error

                # Calculate delay for next retry
                delay = self._calculate_retry_delay(last_error, attempt)
                logger.warning(f"âš ï¸ Retrying in {delay:.2f}s...")
                time.sleep(delay)

        return None, last_error

    def execute_with_fallback(self, func: Callable, fallback_func: Callable,
                            *args, **kwargs) -> Tuple[Any, Optional[ProcessingError]]:
        """
        Execute a function with fallback strategy.

        Args:
            func: Primary function to execute
            fallback_func: Fallback function to execute if primary fails
            *args: Function arguments
            **kwargs: Function keyword arguments

        Returns:
            Tuple of (result, error) where result is from primary or fallback function
        """
        # Try primary function
        result, error = self.execute_with_retry(func, *args, **kwargs)

        if result is not None:
            return result, None

        # Try fallback function
        logger.info(f"ðŸ”„ Attempting fallback function: {fallback_func.__name__}")
        fallback_result, fallback_error = self.execute_with_retry(fallback_func, *args, **kwargs)

        if fallback_result is not None:
            logger.info(f"âœ… Fallback function succeeded: {fallback_func.__name__}")
            return fallback_result, None

        # Both functions failed
        logger.error(f"âŒ Both primary and fallback functions failed")
        return None, error or fallback_error

    def _classify_error(self, error: Exception) -> ErrorCategory:
        """Classify error based on error message and type."""
        error_message = str(error).lower()
        error_type = type(error).__name__.lower()

        # Check error patterns
        for pattern, category in self.error_patterns.items():
            if pattern in error_message or pattern in error_type:
                return category

        # Check specific exception types
        if "bigquery" in error_type or "google" in error_type:
            return ErrorCategory.BIGQUERY
        elif "timeout" in error_type or "timeout" in error_message:
            return ErrorCategory.TIMEOUT
        elif "connection" in error_type or "network" in error_type:
            return ErrorCategory.NETWORK
        elif "memory" in error_type or "resource" in error_type:
            return ErrorCategory.SYSTEM
        elif "value" in error_type or "validation" in error_type:
            return ErrorCategory.INPUT_VALIDATION

        return ErrorCategory.UNKNOWN

    def _determine_severity(self, error: Exception, category: ErrorCategory) -> ErrorSeverity:
        """Determine error severity based on category and context."""
        if category == ErrorCategory.INPUT_VALIDATION:
            return ErrorSeverity.MEDIUM
        elif category == ErrorCategory.AI_MODEL:
            return ErrorSeverity.HIGH
        elif category == ErrorCategory.BIGQUERY:
            return ErrorSeverity.HIGH
        elif category == ErrorCategory.SYSTEM:
            return ErrorSeverity.CRITICAL
        elif category == ErrorCategory.NETWORK:
            return ErrorSeverity.MEDIUM
        elif category == ErrorCategory.TIMEOUT:
            return ErrorSeverity.MEDIUM
        else:
            return ErrorSeverity.LOW

    def _is_retryable(self, error: Exception, category: ErrorCategory) -> bool:
        """Determine if an error is retryable."""
        non_retryable_patterns = [
            "permission denied",
            "invalid credentials",
            "quota exceeded",
            "table not found",
            "dataset not found",
            "missing required field",
            "invalid format"
        ]

        error_message = str(error).lower()

        for pattern in non_retryable_patterns:
            if pattern in error_message:
                return False

        # Category-based retryability
        if category == ErrorCategory.INPUT_VALIDATION:
            return False
        elif category in [ErrorCategory.AI_MODEL, ErrorCategory.BIGQUERY,
                         ErrorCategory.NETWORK, ErrorCategory.TIMEOUT]:
            return True

        return True

    def _calculate_retry_delay(self, error: ProcessingError, attempt: int) -> float:
        """Calculate retry delay using exponential backoff with jitter."""
        config = self.retry_configs[error.category]

        # Exponential backoff
        delay = config.base_delay * (config.exponential_base ** (attempt - 1))

        # Apply maximum delay limit
        delay = min(delay, config.max_delay)

        # Add jitter if configured
        if config.jitter:
            import random
            jitter = random.uniform(0, delay * 0.1)  # 10% jitter
            delay += jitter

        return delay

    def _log_error(self, error: ProcessingError):
        """Log error information."""
        self.error_log.append(error)

        # Log based on severity
        if error.severity == ErrorSeverity.CRITICAL:
            logger.critical(f"ðŸš¨ CRITICAL ERROR [{error.error_id}]: {error.message}")
        elif error.severity == ErrorSeverity.HIGH:
            logger.error(f"âŒ HIGH SEVERITY ERROR [{error.error_id}]: {error.message}")
        elif error.severity == ErrorSeverity.MEDIUM:
            logger.warning(f"âš ï¸ MEDIUM SEVERITY ERROR [{error.error_id}]: {error.message}")
        else:
            logger.info(f"â„¹ï¸ LOW SEVERITY ERROR [{error.error_id}]: {error.message}")

    # Fallback strategy implementations
    def _fallback_simple_extraction(self, *args, **kwargs):
        """Fallback to simple keyword-based extraction."""
        logger.info("ðŸ”„ Using fallback: simple keyword extraction")
        # Implementation would go here
        return {"extraction_method": "fallback_keyword", "status": "success"}

    def _fallback_keyword_analysis(self, *args, **kwargs):
        """Fallback to basic keyword analysis."""
        logger.info("ðŸ”„ Using fallback: keyword analysis")
        # Implementation would go here
        return {"analysis_method": "fallback_keyword", "status": "success"}

    def _fallback_local_storage(self, *args, **kwargs):
        """Fallback to local storage when BigQuery fails."""
        logger.info("ðŸ”„ Using fallback: local storage")
        # Implementation would go here
        return {"storage_method": "fallback_local", "status": "success"}

    def _fallback_retry_later(self, *args, **kwargs):
        """Fallback to retry later when BigQuery is unavailable."""
        logger.info("ðŸ”„ Using fallback: retry later")
        # Implementation would go here
        return {"retry_method": "fallback_later", "status": "deferred"}

    def _fallback_offline_mode(self, *args, **kwargs):
        """Fallback to offline mode when network fails."""
        logger.info("ðŸ”„ Using fallback: offline mode")
        # Implementation would go here
        return {"mode": "fallback_offline", "status": "success"}

    def _fallback_cached_results(self, *args, **kwargs):
        """Fallback to cached results when network fails."""
        logger.info("ðŸ”„ Using fallback: cached results")
        # Implementation would go here
        return {"source": "fallback_cache", "status": "success"}

    def _fallback_reduce_complexity(self, *args, **kwargs):
        """Fallback to reduced complexity processing when timeout occurs."""
        logger.info("ðŸ”„ Using fallback: reduced complexity")
        # Implementation would go here
        return {"complexity": "fallback_reduced", "status": "success"}

    def _fallback_batch_processing(self, *args, **kwargs):
        """Fallback to batch processing when timeout occurs."""
        logger.info("ðŸ”„ Using fallback: batch processing")
        # Implementation would go here
        return {"processing": "fallback_batch", "status": "success"}

    def get_error_summary(self) -> Dict[str, Any]:
        """Get summary of all errors."""
        if not self.error_log:
            return {"total_errors": 0}

        # Count errors by category and severity
        category_counts = {}
        severity_counts = {}

        for error in self.error_log:
            category_counts[error.category.value] = category_counts.get(error.category.value, 0) + 1
            severity_counts[error.severity.value] = severity_counts.get(error.severity.value, 0) + 1

        return {
            "total_errors": len(self.error_log),
            "category_counts": category_counts,
            "severity_counts": severity_counts,
            "recent_errors": [
                {
                    "error_id": error.error_id,
                    "category": error.category.value,
                    "severity": error.severity.value,
                    "message": error.message,
                    "timestamp": error.timestamp.isoformat(),
                    "retryable": error.retryable
                }
                for error in self.error_log[-10:]  # Last 10 errors
            ]
        }

def main():
    """Test the error handler."""
    print("ðŸ”„ Error Handler - Phase 3 Implementation")
    print("=" * 60)

    # This would be used in integration tests
    print("âœ… Error handler class created successfully")

if __name__ == "__main__":
    main()
