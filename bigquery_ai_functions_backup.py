"""
BigQuery AI Functions Implementation
Legal Document Intelligence Platform - BigQuery AI Hackathon Entry

This module implements the core BigQuery AI functions for legal document processing:
- ML.GENERATE_TEXT for document summarization
- AI.GENERATE_TABLE for legal data extraction
- AI.GENERATE_BOOL for urgency detection
- AI.FORECAST for case outcome prediction
"""

import logging
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class BigQueryAIFunctions:
    """Implements BigQuery AI functions for legal document processing."""

    def __init__(self, project_id: str, dataset_id: str = "legal_ai_platform"):
        """
        Initialize BigQuery AI functions.

        Args:
            project_id: Google Cloud project ID
            dataset_id: BigQuery dataset ID
        """
        self.project_id = project_id
        self.dataset_id = dataset_id
        self.model_name = "gemini-pro"

        # Legal document prompts
        self.prompts = {
            'summarization': {
                'contract': "Summarize this legal contract in 3 sentences, focusing on key terms, parties, and obligations:",
                'case_file': "Summarize this legal case in 3 sentences, focusing on key facts, legal issues, and court decision:",
                'legal_brief': "Summarize this legal brief in 3 sentences, focusing on main arguments, legal authorities, and requested relief:",
                'statute': "Summarize this legal statute in 3 sentences, focusing on purpose, key provisions, and scope:",
                'default': "Summarize this legal document in 3 sentences, focusing on key legal issues and outcomes:"
            },
            'extraction': {
                'contract': "Extract key information from this contract including parties, terms, obligations, and key dates:",
                'case_file': "Extract key information from this case including parties, legal issues, facts, and court decision:",
                'legal_brief': "Extract key information from this brief including arguments, legal authorities, facts, and requested relief:",
                'statute': "Extract key information from this statute including purpose, key provisions, scope, and effective dates:",
                'default': "Extract key legal information from this document including parties, issues, facts, and outcomes:"
            },
            'urgency': {
                'contract': "Is this contract urgent? Consider deadlines, expiration dates, and time-sensitive obligations:",
                'case_file': "Is this legal case urgent? Consider filing deadlines, court dates, and time-sensitive legal matters:",
                'legal_brief': "Is this legal brief urgent? Consider filing deadlines, court dates, and time-sensitive legal matters:",
                'statute': "Is this statute urgent? Consider effective dates, compliance deadlines, and time-sensitive requirements:",
                'default': "Is this legal document urgent? Consider deadlines, emergency situations, and time-sensitive matters:"
            }
        }

    def generate_document_summary(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate document summary using ML.GENERATE_TEXT.

        Args:
            document: Legal document dictionary

        Returns:
            Summary result with generated text
        """
        logger.info(f"Generating summary for document: {document.get('document_id', 'unknown')}")

        doc_type = document.get('document_type', 'default')
        content = document.get('cleaned_content', document.get('content', ''))

        if not content:
            return {
                'document_id': document.get('document_id'),
                'summary': '',
                'error': 'No content available for summarization',
                'timestamp': datetime.now().isoformat()
            }

        # Get appropriate prompt for document type
        prompt_template = self.prompts['summarization'].get(doc_type, self.prompts['summarization']['default'])
        prompt = f"{prompt_template}\n\n{content[:4000]}"  # Limit content to avoid token limits

        # Generate BigQuery SQL for ML.GENERATE_TEXT
        sql_query = f"""
        SELECT
          '{document.get('document_id', 'unknown')}' as document_id,
          ML.GENERATE_TEXT(
            MODEL `{self.model_name}`,
            '{prompt.replace("'", "\\'")}'
          ) as summary
        """

        result = {
            'document_id': document.get('document_id'),
            'document_type': doc_type,
            'prompt_used': prompt_template,
            'sql_query': sql_query,
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"Summary generation completed for document: {document.get('document_id', 'unknown')}")
        return result

    def extract_legal_data(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract legal data using AI.GENERATE_TABLE.

        Args:
            document: Legal document dictionary

        Returns:
            Extracted legal data result
        """
        logger.info(f"Extracting legal data for document: {document.get('document_id', 'unknown')}")

        doc_type = document.get('document_type', 'default')
        content = document.get('cleaned_content', document.get('content', ''))

        if not content:
            return {
                'document_id': document.get('document_id'),
                'extracted_data': {},
                'error': 'No content available for extraction',
                'timestamp': datetime.now().isoformat()
            }

        # Define output schema based on document type
        output_schema = self._get_extraction_schema(doc_type)

        # Get appropriate prompt for document type
        prompt_template = self.prompts['extraction'].get(doc_type, self.prompts['extraction']['default'])
        prompt = f"{prompt_template}\n\n{content[:4000]}"  # Limit content to avoid token limits

        # Generate BigQuery SQL for AI.GENERATE_TABLE
        sql_query = f"""
        SELECT
          '{document.get('document_id', 'unknown')}' as document_id,
          AI.GENERATE_TABLE(
            MODEL `{self.model_name}`,
            '{prompt.replace("'", "\\'")}',
            STRUCT('{output_schema}' AS output_schema)
          ) as extracted_data
        """

        result = {
            'document_id': document.get('document_id'),
            'document_type': doc_type,
            'output_schema': output_schema,
            'prompt_used': prompt_template,
            'sql_query': sql_query,
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"Legal data extraction completed for document: {document.get('document_id', 'unknown')}")
        return result

    def detect_urgency(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect document urgency using AI.GENERATE_BOOL.

        Args:
            document: Legal document dictionary

        Returns:
            Urgency detection result
        """
        logger.info(f"Detecting urgency for document: {document.get('document_id', 'unknown')}")

        doc_type = document.get('document_type', 'default')
        content = document.get('cleaned_content', document.get('content', ''))

        if not content:
            return {
                'document_id': document.get('document_id'),
                'is_urgent': False,
                'error': 'No content available for urgency detection',
                'timestamp': datetime.now().isoformat()
            }

        # Get appropriate prompt for document type
        prompt_template = self.prompts['urgency'].get(doc_type, self.prompts['urgency']['default'])
        prompt = f"{prompt_template}\n\n{content[:4000]}"  # Limit content to avoid token limits

        # Generate BigQuery SQL for AI.GENERATE_BOOL
        sql_query = f"""
        SELECT
          '{document.get('document_id', 'unknown')}' as document_id,
          AI.GENERATE_BOOL(
            MODEL `{self.model_name}`,
            '{prompt.replace("'", "\\'")}'
          ) as is_urgent
        """

        result = {
            'document_id': document.get('document_id'),
            'document_type': doc_type,
            'prompt_used': prompt_template,
            'sql_query': sql_query,
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"Urgency detection completed for document: {document.get('document_id', 'unknown')}")
        return result

    def forecast_case_outcome(self, case_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Forecast case outcome using AI.FORECAST.

        Args:
            case_data: Case data dictionary with time series information

        Returns:
            Forecast result
        """
        logger.info(f"Forecasting case outcome for: {case_data.get('case_id', 'unknown')}")

        # AI.FORECAST requires time series data
        # For legal cases, we'll use case volume trends or similar time series data
        time_series_data = case_data.get('time_series_data', [])

        if not time_series_data:
            return {
                'case_id': case_data.get('case_id'),
                'forecast': {},
                'error': 'No time series data available for forecasting',
                'timestamp': datetime.now().isoformat()
            }

        # Generate BigQuery SQL for AI.FORECAST
        # This would typically be used with actual time series data in BigQuery
        sql_query = f"""
        SELECT
          '{case_data.get('case_id', 'unknown')}' as case_id,
          AI.FORECAST(
            MODEL `{self.model_name}`,
            {json.dumps(time_series_data)},
            6  -- Forecast 6 periods ahead
          ) as forecast
        """

        result = {
            'case_id': case_data.get('case_id'),
            'time_series_data': time_series_data,
            'forecast_periods': 6,
            'sql_query': sql_query,
            'timestamp': datetime.now().isoformat()
        }

        logger.info(f"Case outcome forecasting completed for: {case_data.get('case_id', 'unknown')}")
        return result

    def _get_extraction_schema(self, doc_type: str) -> str:
        """
        Get output schema for AI.GENERATE_TABLE based on document type.

        Args:
            doc_type: Document type

        Returns:
            Output schema string
        """
        schemas = {
            'contract': """
            parties ARRAY<STRING>,
            key_terms ARRAY<STRING>,
            obligations ARRAY<STRING>,
            key_dates ARRAY<STRING>,
            termination_clauses ARRAY<STRING>,
            payment_terms ARRAY<STRING>
            """,
            'case_file': """
            plaintiff STRING,
            defendant STRING,
            legal_issues ARRAY<STRING>,
            key_facts ARRAY<STRING>,
            court_decision STRING,
            case_outcome STRING
            """,
            'legal_brief': """
            main_arguments ARRAY<STRING>,
            legal_authorities ARRAY<STRING>,
            key_facts ARRAY<STRING>,
            requested_relief ARRAY<STRING>,
            legal_standards ARRAY<STRING>
            """,
            'statute': """
            purpose STRING,
            key_provisions ARRAY<STRING>,
            scope STRING,
            effective_date STRING,
            penalties ARRAY<STRING>
            """,
            'default': """
            parties ARRAY<STRING>,
            legal_issues ARRAY<STRING>,
            key_facts ARRAY<STRING>,
            outcomes ARRAY<STRING>,
            legal_theories ARRAY<STRING>
            """
        }

        return schemas.get(doc_type, schemas['default']).strip()

    def process_document_with_ai(self, document: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process document with all AI functions.

        Args:
            document: Legal document dictionary

        Returns:
            Complete AI processing results
        """
        logger.info(f"Processing document with AI functions: {document.get('document_id', 'unknown')}")

        results = {
            'document_id': document.get('document_id'),
            'document_type': document.get('document_type'),
            'processing_timestamp': datetime.now().isoformat(),
            'ai_results': {}
        }

        try:
            # Generate summary
            summary_result = self.generate_document_summary(document)
            results['ai_results']['summary'] = summary_result

            # Extract legal data
            extraction_result = self.extract_legal_data(document)
            results['ai_results']['extraction'] = extraction_result

            # Detect urgency
            urgency_result = self.detect_urgency(document)
            results['ai_results']['urgency'] = urgency_result

            # Add success flag
            results['success'] = True

        except Exception as e:
            logger.error(f"Error processing document with AI: {e}")
            results['success'] = False
            results['error'] = str(e)

        logger.info(f"AI processing completed for document: {document.get('document_id', 'unknown')}")
        return results

    def batch_process_documents(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Process multiple documents with AI functions.

        Args:
            documents: List of legal documents

        Returns:
            List of AI processing results
        """
        logger.info(f"Batch processing {len(documents)} documents with AI functions")

        results = []
        for i, document in enumerate(documents):
            try:
                result = self.process_document_with_ai(document)
                results.append(result)

                if (i + 1) % 50 == 0:
                    logger.info(f"Processed {i + 1}/{len(documents)} documents")

            except Exception as e:
                logger.error(f"Error processing document {document.get('document_id', 'unknown')}: {e}")
                error_result = {
                    'document_id': document.get('document_id'),
                    'success': False,
                    'error': str(e),
                    'processing_timestamp': datetime.now().isoformat()
                }
                results.append(error_result)

        logger.info(f"Batch AI processing completed: {len(results)} documents processed")
        return results

    def generate_bigquery_queries(self, documents: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """
        Generate BigQuery SQL queries for batch processing.

        Args:
            documents: List of legal documents

        Returns:
            Dictionary of SQL queries by function type
        """
        logger.info(f"Generating BigQuery queries for {len(documents)} documents")

        queries = {
            'summarization': [],
            'extraction': [],
            'urgency': []
        }

        for document in documents:
            # Generate summary query
            summary_result = self.generate_document_summary(document)
            queries['summarization'].append(summary_result['sql_query'])

            # Generate extraction query
            extraction_result = self.extract_legal_data(document)
            queries['extraction'].append(extraction_result['sql_query'])

            # Generate urgency query
            urgency_result = self.detect_urgency(document)
            queries['urgency'].append(urgency_result['sql_query'])

        logger.info(f"Generated {sum(len(q) for q in queries.values())} BigQuery queries")
        return queries

def main():
    """Test the BigQuery AI functions implementation."""
    print("ü§ñ BigQuery AI Functions Implementation - Phase 2.3")
    print("=" * 70)

    # Initialize AI functions
    ai_functions = BigQueryAIFunctions("faizal-hackathon")

    # Load sample data for testing
    from data.ingestion import LegalDataIngestion
    ingestion = LegalDataIngestion()
    datasets = ingestion.load_legal_datasets()

    # Get first few documents for testing
    sample_docs = datasets['sample_legal_docs']['documents'][:3]

    print(f"üìã Testing BigQuery AI functions with {len(sample_docs)} sample documents")

    # Test each AI function
    for i, doc in enumerate(sample_docs):
        print(f"\nüìÑ Document {i+1}: {doc['document_id']}")
        print(f"  Type: {doc['document_type']}")

        # Test summarization
        print(f"  üîç Testing ML.GENERATE_TEXT (Summarization)")
        summary_result = ai_functions.generate_document_summary(doc)
        print(f"    SQL Query Length: {len(summary_result['sql_query'])} characters")

        # Test extraction
        print(f"  üìä Testing AI.GENERATE_TABLE (Extraction)")
        extraction_result = ai_functions.extract_legal_data(doc)
        print(f"    Output Schema: {extraction_result['output_schema'][:50]}...")

        # Test urgency detection
        print(f"  ‚ö° Testing AI.GENERATE_BOOL (Urgency)")
        urgency_result = ai_functions.detect_urgency(doc)
        print(f"    Prompt Used: {urgency_result['prompt_used'][:50]}...")

    # Test batch processing
    print(f"\nüîÑ Testing Batch Processing")
    batch_results = ai_functions.batch_process_documents(sample_docs)
    print(f"  Processed {len(batch_results)} documents")
    print(f"  Success rate: {sum(1 for r in batch_results if r.get('success', False)) / len(batch_results) * 100:.1f}%")

    # Test query generation
    print(f"\nüìù Testing Query Generation")
    queries = ai_functions.generate_bigquery_queries(sample_docs)
    print(f"  Generated {len(queries['summarization'])} summarization queries")
    print(f"  Generated {len(queries['extraction'])} extraction queries")
    print(f"  Generated {len(queries['urgency'])} urgency queries")

    print(f"\n‚úÖ BigQuery AI functions implementation test completed successfully")

if __name__ == "__main__":
    main()
